digraph {
	graph [size="28.95,28.95"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2623351829472 [label="
 (1, 10)" fillcolor=darkolivegreen1]
	2623389041616 -> 2623351829552 [dir=none]
	2623351829552 [label="mat1
 (1, 128)" fillcolor=orange]
	2623389041616 -> 2623351822592 [dir=none]
	2623351822592 [label="mat2
 (128, 10)" fillcolor=orange]
	2623389041616 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (1, 128)
mat1_sym_strides:       (128, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :      (128, 10)
mat2_sym_strides:       (1, 128)"]
	2623389184256 -> 2623389041616
	2623351830352 [label="classifier.3.bias
 (10)" fillcolor=lightblue]
	2623351830352 -> 2623389184256
	2623389184256 [label=AccumulateGrad]
	2623405564368 -> 2623389041616
	2623405564368 -> 2623351828512 [dir=none]
	2623351828512 [label="other
 (1, 128)" fillcolor=orange]
	2623405564368 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	2623433970288 -> 2623405564368
	2623433970288 -> 2623351828352 [dir=none]
	2623351828352 [label="result
 (1, 128)" fillcolor=orange]
	2623433970288 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	2623433970480 -> 2623433970288
	2623433970480 -> 2623351829632 [dir=none]
	2623351829632 [label="mat1
 (1, 800)" fillcolor=orange]
	2623433970480 -> 2623351829392 [dir=none]
	2623351829392 [label="mat2
 (800, 128)" fillcolor=orange]
	2623433970480 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (1, 800)
mat1_sym_strides:       (800, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :     (800, 128)
mat2_sym_strides:       (1, 800)"]
	2623433970576 -> 2623433970480
	2623351830432 [label="classifier.0.bias
 (128)" fillcolor=lightblue]
	2623351830432 -> 2623433970576
	2623433970576 [label=AccumulateGrad]
	2623433970384 -> 2623433970480
	2623433970384 [label="ViewBackward0
-----------------------------
self_sym_sizes: (1, 32, 5, 5)"]
	2623433972352 -> 2623433970384
	2623433972352 -> 2623351829792 [dir=none]
	2623351829792 [label="self
 (1, 32, 5, 27)" fillcolor=orange]
	2623433972352 [label="AdaptiveAvgPool2DBackward0
--------------------------
self: [saved tensor]"]
	2623433972160 -> 2623433972352
	2623433972160 -> 2623351821552 [dir=none]
	2623351821552 [label="result1
 (1, 32, 5, 27)" fillcolor=orange]
	2623433972160 -> 2623351822752 [dir=none]
	2623351822752 [label="self
 (1, 32, 10, 54)" fillcolor=orange]
	2623433972160 [label="MaxPool2DWithIndicesBackward0
-----------------------------
ceil_mode  :          False
dilation   :         (1, 1)
kernel_size:         (2, 2)
padding    :         (0, 0)
result1    : [saved tensor]
self       : [saved tensor]
stride     :         (2, 2)"]
	2623428836320 -> 2623433972160
	2623428836320 -> 2623351819552 [dir=none]
	2623351819552 [label="result
 (1, 32, 10, 54)" fillcolor=orange]
	2623428836320 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	2623433972448 -> 2623428836320
	2623433972448 -> 2623351829872 [dir=none]
	2623351829872 [label="input
 (1, 32, 10, 54)" fillcolor=orange]
	2623433972448 -> 2623351825712 [dir=none]
	2623351825712 [label="result1
 (32)" fillcolor=orange]
	2623433972448 -> 2623351832512 [dir=none]
	2623351832512 [label="result2
 (32)" fillcolor=orange]
	2623433972448 -> 2623351830912 [dir=none]
	2623351830912 [label="running_mean
 (32)" fillcolor=orange]
	2623433972448 -> 2623351823712 [dir=none]
	2623351823712 [label="running_var
 (32)" fillcolor=orange]
	2623433972448 -> 2623351830832 [dir=none]
	2623351830832 [label="weight
 (32)" fillcolor=orange]
	2623433972448 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	2623433971872 -> 2623433972448
	2623433971872 -> 2623351822912 [dir=none]
	2623351822912 [label="input
 (1, 16, 10, 54)" fillcolor=orange]
	2623433971872 -> 2623351823872 [dir=none]
	2623351823872 [label="weight
 (32, 16, 1, 1)" fillcolor=orange]
	2623433971872 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	2623429854064 -> 2623433971872
	2623429854064 -> 2623351830032 [dir=none]
	2623351830032 [label="input
 (1, 16, 10, 54)" fillcolor=orange]
	2623429854064 -> 2623351830992 [dir=none]
	2623351830992 [label="weight
 (16, 1, 3, 3)" fillcolor=orange]
	2623429854064 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :             16
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	2623433971296 -> 2623429854064
	2623433971296 -> 2623351728208 [dir=none]
	2623351728208 [label="result1
 (1, 16, 10, 54)" fillcolor=orange]
	2623433971296 -> 2623351829952 [dir=none]
	2623351829952 [label="self
 (1, 16, 20, 108)" fillcolor=orange]
	2623433971296 [label="MaxPool2DWithIndicesBackward0
-----------------------------
ceil_mode  :          False
dilation   :         (1, 1)
kernel_size:         (2, 2)
padding    :         (0, 0)
result1    : [saved tensor]
self       : [saved tensor]
stride     :         (2, 2)"]
	2623433972496 -> 2623433971296
	2623433972496 -> 2623351727968 [dir=none]
	2623351727968 [label="result
 (1, 16, 20, 108)" fillcolor=orange]
	2623433972496 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	2623433971392 -> 2623433972496
	2623433971392 -> 2623351823072 [dir=none]
	2623351823072 [label="input
 (1, 16, 20, 108)" fillcolor=orange]
	2623433971392 -> 2623351727808 [dir=none]
	2623351727808 [label="result1
 (16)" fillcolor=orange]
	2623433971392 -> 2623351728528 [dir=none]
	2623351728528 [label="result2
 (16)" fillcolor=orange]
	2623433971392 -> 2623351831472 [dir=none]
	2623351831472 [label="running_mean
 (16)" fillcolor=orange]
	2623433971392 -> 2623351824432 [dir=none]
	2623351824432 [label="running_var
 (16)" fillcolor=orange]
	2623433971392 -> 2623351818272 [dir=none]
	2623351818272 [label="weight
 (16)" fillcolor=orange]
	2623433971392 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	2623433971152 -> 2623433971392
	2623433971152 -> 2623351830272 [dir=none]
	2623351830272 [label="input
 (1, 8, 20, 108)" fillcolor=orange]
	2623433971152 -> 2623351831392 [dir=none]
	2623351831392 [label="weight
 (16, 8, 1, 1)" fillcolor=orange]
	2623433971152 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	2623433971536 -> 2623433971152
	2623433971536 -> 2623351830192 [dir=none]
	2623351830192 [label="input
 (1, 8, 20, 108)" fillcolor=orange]
	2623433971536 -> 2623351824512 [dir=none]
	2623351824512 [label="weight
 (8, 1, 3, 3)" fillcolor=orange]
	2623433971536 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              8
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	2623433972784 -> 2623433971536
	2623433972784 -> 2623351727488 [dir=none]
	2623351727488 [label="result1
 (1, 8, 20, 108)" fillcolor=orange]
	2623433972784 -> 2623351830112 [dir=none]
	2623351830112 [label="self
 (1, 8, 40, 216)" fillcolor=orange]
	2623433972784 [label="MaxPool2DWithIndicesBackward0
-----------------------------
ceil_mode  :          False
dilation   :         (1, 1)
kernel_size:         (2, 2)
padding    :         (0, 0)
result1    : [saved tensor]
self       : [saved tensor]
stride     :         (2, 2)"]
	2623433972064 -> 2623433972784
	2623433972064 -> 2623351727168 [dir=none]
	2623351727168 [label="result
 (1, 8, 40, 216)" fillcolor=orange]
	2623433972064 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	2623433972688 -> 2623433972064
	2623433972688 -> 2623351823232 [dir=none]
	2623351823232 [label="input
 (1, 8, 40, 216)" fillcolor=orange]
	2623433972688 -> 2623351726688 [dir=none]
	2623351726688 [label="result1
 (8)" fillcolor=orange]
	2623433972688 -> 2623351726848 [dir=none]
	2623351726848 [label="result2
 (8)" fillcolor=orange]
	2623433972688 -> 2623351831952 [dir=none]
	2623351831952 [label="running_mean
 (8)" fillcolor=orange]
	2623433972688 -> 2623351831712 [dir=none]
	2623351831712 [label="running_var
 (8)" fillcolor=orange]
	2623433972688 -> 2623351824832 [dir=none]
	2623351824832 [label="weight
 (8)" fillcolor=orange]
	2623433972688 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :           True
weight      : [saved tensor]"]
	2623433971200 -> 2623433972688
	2623433971200 -> 2623351823552 [dir=none]
	2623351823552 [label="input
 (1, 3, 40, 216)" fillcolor=orange]
	2623433971200 -> 2623351831872 [dir=none]
	2623351831872 [label="weight
 (8, 3, 3, 3)" fillcolor=orange]
	2623433971200 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	2623433972544 -> 2623433971200
	2623351831872 [label="conv1.0.weight
 (8, 3, 3, 3)" fillcolor=lightblue]
	2623351831872 -> 2623433972544
	2623433972544 [label=AccumulateGrad]
	2623433972832 -> 2623433972688
	2623351824832 [label="conv1.1.weight
 (8)" fillcolor=lightblue]
	2623351824832 -> 2623433972832
	2623433972832 [label=AccumulateGrad]
	2623433973072 -> 2623433972688
	2623351831792 [label="conv1.1.bias
 (8)" fillcolor=lightblue]
	2623351831792 -> 2623433973072
	2623433973072 [label=AccumulateGrad]
	2623433972880 -> 2623433971536
	2623351824512 [label="conv2.depthwise.weight
 (8, 1, 3, 3)" fillcolor=lightblue]
	2623351824512 -> 2623433972880
	2623433972880 [label=AccumulateGrad]
	2623433971344 -> 2623433971152
	2623351831392 [label="conv2.pointwise.weight
 (16, 8, 1, 1)" fillcolor=lightblue]
	2623351831392 -> 2623433971344
	2623433971344 [label=AccumulateGrad]
	2623433971920 -> 2623433971392
	2623351818272 [label="conv2.bn.weight
 (16)" fillcolor=lightblue]
	2623351818272 -> 2623433971920
	2623433971920 [label=AccumulateGrad]
	2623433971632 -> 2623433971392
	2623351818192 [label="conv2.bn.bias
 (16)" fillcolor=lightblue]
	2623351818192 -> 2623433971632
	2623433971632 [label=AccumulateGrad]
	2623433971440 -> 2623429854064
	2623351830992 [label="conv3.depthwise.weight
 (16, 1, 3, 3)" fillcolor=lightblue]
	2623351830992 -> 2623433971440
	2623433971440 [label=AccumulateGrad]
	2623433972256 -> 2623433971872
	2623351823872 [label="conv3.pointwise.weight
 (32, 16, 1, 1)" fillcolor=lightblue]
	2623351823872 -> 2623433972256
	2623433972256 [label=AccumulateGrad]
	2623433972400 -> 2623433972448
	2623351830832 [label="conv3.bn.weight
 (32)" fillcolor=lightblue]
	2623351830832 -> 2623433972400
	2623433972400 [label=AccumulateGrad]
	2623433971824 -> 2623433972448
	2623351830752 [label="conv3.bn.bias
 (32)" fillcolor=lightblue]
	2623351830752 -> 2623433971824
	2623433971824 [label=AccumulateGrad]
	2623433969808 -> 2623433970480
	2623433969808 [label=TBackward0]
	2623433971968 -> 2623433969808
	2623351830512 [label="classifier.0.weight
 (128, 800)" fillcolor=lightblue]
	2623351830512 -> 2623433971968
	2623433971968 [label=AccumulateGrad]
	2623432994304 -> 2623389041616
	2623432994304 [label=TBackward0]
	2623433972112 -> 2623432994304
	2623351823392 [label="classifier.3.weight
 (10, 128)" fillcolor=lightblue]
	2623351823392 -> 2623433972112
	2623433972112 [label=AccumulateGrad]
	2623389041616 -> 2623351829472
	dpi=300
	rankdir=TB
	fontsize=20
	concentrate=true
}
